--- a/Onboard/Appearance.py
+++ b/Onboard/Appearance.py
@@ -921,7 +921,7 @@ class ColorScheme(object):
         ColorScheme._parse_dom_node_item(node, item)
         return item
 
-    _key_ids_pattern = re.compile('[\w-]+(?:[.][\w-]+)?', re.UNICODE)
+    _key_ids_pattern = re.compile(r'[\w-]+(?:[.][\w-]+)?', re.UNICODE)
 
     @staticmethod
     def _parse_key_group(node, used_keys):
@@ -1063,7 +1063,7 @@ class ColorScheme(object):
 
             # read key ids
             text = "".join([n.data for n in group.childNodes])
-            key_ids = [x for x in re.findall('\w+(?:[.][\w-]+)?', text) if x]
+            key_ids = [x for x in re.findall(r'\w+(?:[.][\w-]+)?', text) if x]
 
             # check for duplicate key definitions
             for key_id in key_ids:
--- a/Onboard/LayoutLoaderSVG.py
+++ b/Onboard/LayoutLoaderSVG.py
@@ -95,7 +95,7 @@ class LayoutLoaderSVG:
         self._layout_filename = ""
         self._color_scheme = None
         self._root_layout_dir = ""  # path to svg files
-        self._layout_regex = re.compile("([^\(]+) (?: \( ([^\)]*) \) )?",
+        self._layout_regex = re.compile(r"([^\(]+) (?: \( ([^\)]*) \) )?",
                                         re.VERBOSE)
 
     def load(self, vk, layout_filename, color_scheme):
--- a/Onboard/SpellChecker.py
+++ b/Onboard/SpellChecker.py
@@ -321,7 +321,7 @@ class hunspell(SCBackend):
     def is_running(self):
         return not self._osk_hunspell is None
 
-    SPLITWORDS = re.compile("[^-_\s]+", re.UNICODE|re.DOTALL)
+    SPLITWORDS = re.compile(r"[^-_\s]+", re.UNICODE|re.DOTALL)
 
     def query(self, text):
         """
--- a/Onboard/TextDomain.py
+++ b/Onboard/TextDomain.py
@@ -141,7 +141,7 @@ class TextDomain:
 
         # Split at whitespace to catch whole URLs/file names and
         # keep separators.
-        strings = re.split('(\s+)', context)
+        strings = re.split(r'(\s+)', context)
         if strings:
             string = strings[-1]
             if self._url_parser.is_maybe_url(string):
@@ -158,7 +158,7 @@ class TextDomain:
 
 
     def _search_valid_file_name(self, strings):
-        """
+        r"""
         Search for a valid filename backwards across separators.
 
         Doctests:
@@ -174,17 +174,17 @@ class TextDomain:
         >>> with open(fn2, mode="w") as f: n = f.write("")
 
         # simple file in dir with spaces must return as filename
-        >>> strings = re.split('(\s+)', fn1)
+        >>> strings = re.split(r'(\s+)', fn1)
         >>> "/test onboard" in d._search_valid_file_name(strings)
         True
 
         # file with spaces in dir with spaces must return as filename
-        >>> strings = re.split('(\s+)', fn2)
+        >>> strings = re.split(r'(\s+)', fn2)
         >>> "/test onboard" in d._search_valid_file_name(strings)
         True
 
         # random string after a valid file must not be confused with a filename
-        >>> strings = re.split('(\s+)', fn2 + " no-file")
+        >>> strings = re.split(r'(\s+)', fn2 + " no-file")
         >>> d._search_valid_file_name(strings) is None
         True
         """
@@ -288,7 +288,7 @@ class TextDomain:
     def handle_key_press(self, keycode, mod_mask):
         return True, None  # entering_text, end_of_editing
 
-    _growth_sections_pattern = re.compile("[^\s?#@]+", re.DOTALL)
+    _growth_sections_pattern = re.compile(r"[^\s?#@]+", re.DOTALL)
 
     def _split_growth_sections(self, text):
         """
@@ -444,11 +444,11 @@ class DomainTerminal(TextDomain):
                                 (
                                     "^gdb$ ",
                                     "^>>> ",              # python
-                                    "^In \[[0-9]*\]: ",   # ipython
+                                    r"^In \[[0-9]*\]: ",  # ipython
                                     "^:",                 # vi command mode
                                     "^/",                 # vi search
-                                    "^\?",                # vi reverse search
-                                    "\$ ",                # generic prompt
+                                    r"^\?",               # vi reverse search
+                                    r"\$ ",               # generic prompt
                                     "# ",                 # root prompt
                                     "^.*?@.*?/.*?> "      # fish
                                 )
@@ -456,7 +456,7 @@ class DomainTerminal(TextDomain):
 
     _prompt_blacklist_patterns = tuple(re.compile(p, re.UNICODE) for p in
                                 (
-                                    "^\(.*\)`.*': ",  # bash incremental search
+                                    r"^\(.*\)`.*': ",  # bash incremental search
                                 )
                             )
 
@@ -736,7 +736,7 @@ class PartialURLParser:
     _protocols = ["mailto", "apt"]
     _all_schemes = _schemes + _protocols
 
-    _url_pattern = re.compile("([\w-]+)|(\W+)", re.UNICODE)
+    _url_pattern = re.compile(r"([\w-]+)|(\W+)", re.UNICODE)
 
     def iter_url(self, url):
         return self._url_pattern.finditer(url)
--- a/Onboard/WordSuggestions.py
+++ b/Onboard/WordSuggestions.py
@@ -1250,8 +1250,8 @@ class WordSuggestions:
                 return word_span
         return None
 
-    _section_begin_pattern = re.compile("\S*\s*$")
-    _section_end_pattern = re.compile("\S*(?=\s*)")
+    _section_begin_pattern = re.compile(r"\S*\s*$")
+    _section_end_pattern = re.compile(r"\S*(?=\s*)")
 
     def _get_section_before_span(self, insertion_span):
         """
--- a/Onboard/pypredict/lm_wrapper.py
+++ b/Onboard/pypredict/lm_wrapper.py
@@ -299,7 +299,7 @@ def split_tokens_at(tokens, split_indice
 
 
 SENTENCE_PATTERN = re.compile( \
-    """ .*?
+    r""" .*?
            (?:
                  (?:[.;:!?](?:(?=[\s]) | \")) # punctuation
                | (?:\\s*\\n\\s*)+(?=[\\n])    # multiples newlines
@@ -365,7 +365,7 @@ def split_sentences(text, disambiguate=F
     return sentences, spans
 
 
-tokenize_pattern = """
+tokenize_pattern = r"""
     (                                     # <unk>
       (?:^|(?<=\s))
         \S*(\S)\\2{{3,}}\S*               # char repeated more than 3 times
@@ -464,7 +464,7 @@ def tokenize_context(text):
         The result is ready for use in predict().
     """
     tokens, spans = tokenize_text(text, is_context = True)
-    if not re.match("""
+    if not re.match(r"""
                   ^$                             # empty string?
                 | .*[-'´΄\w]$                    # word at the end?
                 | (?:^|.*\s)[|]=?$               # recognized operator?
@@ -501,7 +501,7 @@ def read_order(filename, encoding=None):
             continue
 
         if data:  # data section?
-            result = re.search("ngram (\d+)=\d+", line)
+            result = re.search(r"ngram (\d+)=\d+", line)
             if result:
                 if order is None:
                     order = 0
@@ -621,7 +621,7 @@ def simulate_typing(query_model, learn_m
             context, spans = tokenize_context(". " + inputline) # simulate sentence begin
             prefix = context[len(context)-1] if context else ""
             prefix_to_end = sentence[len(inputline)-len(prefix):]
-            target_word = re.search("^([\w]|[-'])*", prefix_to_end, re.UNICODE).group()
+            target_word = re.search(r"^([\w]|[-'])*", prefix_to_end, re.UNICODE).group()
             choices = query_model.predict(context, limit)
 
             if 0:  # step mode for debugging
--- a/Onboard/utils.py
+++ b/Onboard/utils.py
@@ -148,7 +148,7 @@ def get_keysym_from_name(name):
     return keysyms[name]
 
 def parse_key_combination(combo, avaliable_key_ids = None):
-    """
+    r"""
     Parses a key combination into a list of modifier masks and key_ids.
     The key-id part of the combo may contain a regex pattern.
 
@@ -169,7 +169,7 @@ def parse_key_combination(combo, avaliab
     [('TAB', 5)]
 
     # regex
-    >>> parse_key_combination(["F\d+"], ["TAB", "F1", "F2", "F3", "F9"])
+    >>> parse_key_combination([r"F\d+"], ["TAB", "F1", "F2", "F3", "F9"])
     [('F1', 0), ('F2', 0), ('F3', 0), ('F9', 0)]
     """
     modifiers = combo[:-1]
@@ -217,8 +217,8 @@ def run_script(script):
 def toprettyxml(domdoc):
     ugly_xml = domdoc.toprettyxml(indent='  ')
     # Join lines with text elements with their tag lines
-    pattern = re.compile('>\n\s+([^<>\s].*?)\n\s+</', re.DOTALL)
-    pretty_xml = pattern.sub('>\g<1></', ugly_xml)
+    pattern = re.compile(r'>\n\s+([^<>\s].*?)\n\s+</', re.DOTALL)
+    pretty_xml = pattern.sub(r'>\g<1></', ugly_xml)
 
     # Work around http://bugs.python.org/issue5752
     pretty_xml = re.sub(
@@ -353,7 +353,7 @@ class dictproperty(object):
         return self._proxy(obj, self._fget, self._fset, self._fdel)
 
 def unpack_name_value_list(_list, num_values=2, key_type = str):
-    """
+    r"""
     Converts a list of strings into a dict of tuples.
     Sample list: ['LWIN:label:super', ...]
     ":" in a value must be escaped as "\:"
@@ -1539,7 +1539,7 @@ class XDGDirs:
 
 
 _tag_pattern = re.compile(
-    """(?:
+    r"""(?:
             <[\w\-_]+                         # tag
             (?:\s+[\w\-_]+=["'][^"']*["'])*  # attributes
             /?>
--- a/setup.py
+++ b/setup.py
@@ -115,7 +115,7 @@ def get_pkg_version(package):
               .format(repr(package), status), file=sys.stderr)
         sys.exit(2)
 
-    version = re.search('(?:(?:\d+)\.)+\d+', output).group()
+    version = re.search(r'(?:(?:\d+)\.)+\d+', output).group()
     components = version.split(".")
     major, minor = int(components[0]), int(components[1])
     revision = int(components[2]) if len(components) >= 3 else 0
